{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learn the Vocabulary**\n",
    "\n",
    "We use the Multi30k dataset for english - german translation. This notebook uses the byte-pair encoding to fit a joint vocabulary for both the English and German language based on the most frequent byte pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import multi30k, Multi30k\n",
    "\n",
    "multi30k.URL[\"train\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n",
    "multi30k.URL[\"valid\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\n",
    "multi30k.URL[\"test\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/mmt16_task1_test.tar.gz\"\n",
    "\n",
    "data = Multi30k()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Zwei junge wei√üe M√§nner sind im Freien in der N√§he vieler B√ºsche.',\n",
       " 'Two young, White males are outside near many bushes.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Zwei junge wei√üe M√§nner sind im Freien in der N√§he vieler B√ºsche.',\n",
       " 'Two young, White males are outside near many bushes.',\n",
       " 'Mehrere M√§nner mit Schutzhelmen bedienen ein Antriebsradsystem.',\n",
       " 'Several men in hard hats are operating a giant pulley system.',\n",
       " 'Ein kleines M√§dchen klettert in ein Spielhaus aus Holz.',\n",
       " 'A little girl climbing into a wooden playhouse.',\n",
       " 'Ein Mann in einem blauen Hemd steht auf einer Leiter und putzt ein Fenster.',\n",
       " 'A man in a blue shirt is standing on a ladder cleaning a window.',\n",
       " 'Zwei M√§nner stehen am Herd und bereiten Essen zu.',\n",
       " 'Two men are at the stove preparing food.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_joint_text_corpus(data):\n",
    "    joint_text = []\n",
    "    for pair in data:\n",
    "        joint_text.append(pair[0])\n",
    "        joint_text.append(pair[1])\n",
    "    return joint_text\n",
    "\n",
    "text_joint_en_de = get_joint_text_corpus(train_data)\n",
    "text_joint_en_de[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How do we turn a text corpus into a fixed length vector?**\n",
    "\n",
    "With the Byte-Pair Encoding. Let's implement it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_corpus_from_data(data, language, n_sentences):\n",
    "    corpus = []\n",
    "    for i in range(n_sentences):\n",
    "        corpus.append(data[i][0 if language == \"german\" else 1])\n",
    "    return corpus\n",
    "\n",
    "N_SENTENCES = 1000\n",
    "english_corpus = extract_corpus_from_data(train_data, \"english\", N_SENTENCES)\n",
    "german_corpus = extract_corpus_from_data(train_data, \"german\", N_SENTENCES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 893/893 [10:19<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to learn vocabulary for universal BPE: 619.11 seconds\n",
      "[INFO] Saving vocabulary data to: data/universal_bpe_encoder.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from byte_pair_encoder import BytePairEncoder\n",
    "import timeit\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = \"data/universal_bpe_encoder.pkl\"\n",
    "if not Path(data_path).exists():\n",
    "    encoder_universal = BytePairEncoder(\"universal\", max_vocab_size=1000, use_start_token=True, use_end_token=True, use_padding_token=True, max_token_len=300)\n",
    "    time = timeit.timeit(lambda: encoder_universal.learn_vocabulary_from_corpus(text_joint_en_de, n_processes=16), number=1)\n",
    "    print(f\"Time to learn vocabulary for universal BPE: {time:.2f} seconds\")\n",
    "    encoder_universal.save_vocabulary(data_path)\n",
    "else:\n",
    "    encoder_universal = BytePairEncoder(\"universal\", max_vocab_size=1000, use_start_token=True, use_end_token=True, use_padding_token=True, max_token_len=300, load_vocabulary_from=data_path)\n",
    "    encoder_universal._max_token_len = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dl_train = DataLoader(data[0], shuffle=True, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wac3st/Development/code/transformer/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/combining.py:297: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    }
   ],
   "source": [
    "sample = next(iter(dl_train))\n",
    "input, labels = sample\n",
    "input = encoder_universal.encode_corpus(list(input))\n",
    "labels = encoder_universal.encode_corpus(list(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ùÑÜEine kleine Band tritt vor Menschen in einem Nachtclub auf.ùÑá‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™', 'ùÑÜEin Junge h√§lt sich an einer Anlegestelle an einem blauen Griff.ùÑá‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™', 'ùÑÜDas kleine Kind steht in einer Kampfsportstellung.ùÑá‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™', 'ùÑÜEin Kleinkind und ein Baby spielen am Ende einer Rutsche.ùÑá‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™']\n",
      "['ùÑÜA small band performing for people in a nightclub.ùÑá‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™', 'ùÑÜA young boy holds onto a blue handle on a pier.ùÑá‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™', 'ùÑÜThe young child is standing in a martial arts pose.ùÑá‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™', 'ùÑÜA toddler and a baby play at the end of a slide.ùÑá‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™‚ô™']\n"
     ]
    }
   ],
   "source": [
    "input_dec = encoder_universal.decode_corpus(input)\n",
    "labels_dec = encoder_universal.decode_corpus(labels)\n",
    "print(input_dec)\n",
    "print(labels_dec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
